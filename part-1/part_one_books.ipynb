{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8eFW_wl1n39","outputId":"60dcbf93-35e3-48d1-de72-143a616d150d","executionInfo":{"status":"ok","timestamp":1669858402600,"user_tz":300,"elapsed":29430,"user":{"displayName":"Anisha Chaudhari","userId":"04176206645505870001"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Waiting for headers] [1\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Waiting for headers] [W\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [2 InRelease 14.2 kB/88.\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.36\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n","Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [1,039 kB]\n","Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n","Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,072 kB]\n","Get:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n","Get:15 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,262 kB]\n","Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,563 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,519 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,342 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,334 kB]\n","Get:21 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [38.5 kB]\n","Fetched 14.5 MB in 4s (3,865 kB/s)\n","Reading package lists... Done\n"]}],"source":["# Activate Spark in our Colab notebook.\n","import os\n","# Find the latest version of spark 3.2  from http://www.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.2.2'\n","spark_version = 'spark-3.2.3'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BzCrgs0Z1rnw","outputId":"2a2eaee8-c6ca-49ea-bbd5-546c8ff1073d","executionInfo":{"status":"ok","timestamp":1669858411455,"user_tz":300,"elapsed":375,"user":{"displayName":"Anisha Chaudhari","userId":"04176206645505870001"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-12-01 01:33:31--  https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n","Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n","Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 914037 (893K) [application/java-archive]\n","Saving to: ‘postgresql-42.2.9.jar’\n","\n","postgresql-42.2.9.j 100%[===================>] 892.61K  --.-KB/s    in 0.08s   \n","\n","2022-12-01 01:33:31 (10.3 MB/s) - ‘postgresql-42.2.9.jar’ saved [914037/914037]\n","\n"]}],"source":["# Get postgresql package\n","!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"0DuBth0V2PR8","executionInfo":{"status":"ok","timestamp":1669859406313,"user_tz":300,"elapsed":100,"user":{"displayName":"Anisha Chaudhari","userId":"04176206645505870001"}}},"outputs":[],"source":["# Import Spark and create a SparkSession\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"booksdb\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()"]},{"cell_type":"markdown","metadata":{"id":"D3W2XJVi2CU-"},"source":["# Extract the Amazon Data into Spark DataFrame"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Na_stw7b1wfU","outputId":"7c08588f-711b-4ead-8306-2289260d090d","executionInfo":{"status":"ok","timestamp":1669858521146,"user_tz":300,"elapsed":93057,"user":{"displayName":"Anisha Chaudhari","userId":"04176206645505870001"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n","|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|review_date|\n","+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n","|         US|   12076615| RQ58W7SMO911M|0385730586|     122662979|Sisterhood of the...|           Books|          4|            2|          3|   N|                N|this book was a g...|this boook was a ...| 2005-10-14|\n","|         US|   12703090|  RF6IUKMGL8SF|0811828964|      56191234|The Bad Girl's Gu...|           Books|          3|            5|          5|   N|                N|           Fun Fluff|If you are lookin...| 2005-10-14|\n","|         US|   12257412|R1DOSHH6AI622S|1844161560|     253182049|Eisenhorn (A Warh...|           Books|          4|            1|         22|   N|                N| this isn't a review|never read it-a y...| 2005-10-14|\n","|         US|   50732546| RATOTLA3OF70O|0373836635|     348672532|Colby Conspiracy ...|           Books|          5|            2|          2|   N|                N|fine author on he...|Though she is hon...| 2005-10-14|\n","|         US|   51964897|R1TNWRKIVHVYOV|0262181533|     598678717|The Psychology of...|           Books|          4|            0|          2|   N|                N|Execellent cursor...|Review based on a...| 2005-10-14|\n","|         US|   31048862|R2F53LI9KK9MOY|0316769487|     862964341|The Catcher in th...|           Books|          4|            2|          2|   N|                N|   Interesting, fun.|My only complaint...| 2005-10-14|\n","|         US|   53000124|R1KJ6MB7MRSQFF|0805076069|     145341889|Bait and Switch: ...|           Books|          4|            9|         11|   N|                N|I viewed this the...|This book is chil...| 2005-10-14|\n","|         US|   29732693|R2XIM9LT335WHE|1581603681|     640542054|Opening Combinati...|           Books|          4|            3|         10|   N|                N|No Frills - Just ...|When looking for ...| 2005-10-14|\n","|         US|   48541186|R1VE0FQQ0QTQJN|0300108834|     915891133|A Little History ...|           Books|          5|           16|         20|   N|                Y|Simple, entertain...|Never been much f...| 2005-10-14|\n","|         US|   15280864|R1VKEE2NWSWDRU|0446531081|     880645124|Hour Game (King &...|           Books|          4|            0|          0|   N|                N|        A good read!|If you enjoy a we...| 2005-10-14|\n","|         US|   24209213|R2UP6XSVYJBJ2H|0976822105|     731931430|     Faith is a Verb|           Books|          5|            0|          0|   N|                N|Made me Question ...|I thoroughly enjo...| 2005-10-14|\n","|         US|   52253037|R21SYDQ70ILUC0|1580085695|     586052746|Furry Logic: A Gu...|           Books|          5|            1|          1|   N|                Y|    The Perfect Gift|If you are stumpe...| 2005-10-14|\n","|         US|   27925116| R7M06Z88PD7SX|0029148510|      72387289|Acts of War: Beha...|           Books|          4|           14|         14|   N|                N|Solid Book About ...|Whether intention...| 2005-10-14|\n","|         US|   15005044| RRS38KZ4WB5O2|1592285570|     702385650|Temple to the Win...|           Books|          5|            1|          1|   N|                N|A riveting accoun...|Temple to the win...| 2005-10-14|\n","|         US|   52534781|R2YDYRSLGNHPHR|0811848833|     102333549|The Star Wars Pos...|           Books|          4|           16|         19|   N|                Y|Comprehensive vis...|At last... a comp...| 2005-10-14|\n","|         US|   26217071|R1BMPM18O6VZOR|0782144276|     971452783|Photoshop for Nat...|           Books|          4|           13|         14|   N|                N|          Great Book|I find \\\\\"Photosh...| 2005-10-14|\n","|         US|   37684582|R1AABFZH0J0C0C|0375757996|     760991156|The Basic Works o...|           Books|          3|           17|         35|   N|                N|Problems with thi...|I love Aristotle ...| 2005-10-14|\n","|         US|   45232107|R3SJYLG07EHNE9|013146308X|     332774292|The Pterosaurs: F...|           Books|          2|           16|         34|   N|                N|Warmed over lefto...|To his discredit,...| 2005-10-14|\n","|         US|   15437121|R2TIO43ND87XVO|0375701907|     635714194|Straight Man: A N...|           Books|          5|            1|          1|   N|                N|       Funniest Book|Hands down, the f...| 2005-10-14|\n","|         US|   52157117|R18TY4WD19OUAO|141378240X|     656010659|   Lipstick's Legacy|           Books|          5|            1|          1|   N|                N|          Great Work|I read this book ...| 2005-10-14|\n","+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n","only showing top 20 rows\n","\n"]}],"source":["# Read in the data from an S3 Bucket\n","from pyspark import SparkFiles\n","\n","url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Books_v1_02.tsv.gz\"\n","spark.sparkContext.addFile(url)\n","\n","books_df = spark.read.csv(SparkFiles.get(\"amazon_reviews_us_Books_v1_02.tsv.gz\"), sep=\"\\t\", header=True, inferSchema=True)\n","\n","# Show DataFrame\n","books_df.show()\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cayz-3Q52IM3","outputId":"71f32d43-fe73-4a0f-9b9f-dc25f86ffa54","executionInfo":{"status":"ok","timestamp":1669858551582,"user_tz":300,"elapsed":26707,"user":{"displayName":"Anisha Chaudhari","userId":"04176206645505870001"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["3105520"]},"metadata":{},"execution_count":7}],"source":["# Get the number of rows in the DataFrame.\n","\n","books_df.count()"]},{"cell_type":"markdown","metadata":{"id":"C9U0rkGZ2eu7"},"source":["# Transform the Data"]},{"cell_type":"markdown","source":["## Create the \"review_id_table\"."],"metadata":{"id":"dUoftWoKtM_c"}},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2tMYkSIk2d-m","outputId":"0bffce50-14db-41fe-cf46-547b1444fde3","executionInfo":{"status":"ok","timestamp":1669858556265,"user_tz":300,"elapsed":648,"user":{"displayName":"Anisha Chaudhari","userId":"04176206645505870001"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------+-----------+----------+--------------+-----------+\n","|     review_id|customer_id|product_id|product_parent|review_date|\n","+--------------+-----------+----------+--------------+-----------+\n","| RQ58W7SMO911M|   12076615|0385730586|     122662979| 2005-10-14|\n","|  RF6IUKMGL8SF|   12703090|0811828964|      56191234| 2005-10-14|\n","|R1DOSHH6AI622S|   12257412|1844161560|     253182049| 2005-10-14|\n","| RATOTLA3OF70O|   50732546|0373836635|     348672532| 2005-10-14|\n","|R1TNWRKIVHVYOV|   51964897|0262181533|     598678717| 2005-10-14|\n","|R2F53LI9KK9MOY|   31048862|0316769487|     862964341| 2005-10-14|\n","|R1KJ6MB7MRSQFF|   53000124|0805076069|     145341889| 2005-10-14|\n","|R2XIM9LT335WHE|   29732693|1581603681|     640542054| 2005-10-14|\n","|R1VE0FQQ0QTQJN|   48541186|0300108834|     915891133| 2005-10-14|\n","|R1VKEE2NWSWDRU|   15280864|0446531081|     880645124| 2005-10-14|\n","|R2UP6XSVYJBJ2H|   24209213|0976822105|     731931430| 2005-10-14|\n","|R21SYDQ70ILUC0|   52253037|1580085695|     586052746| 2005-10-14|\n","| R7M06Z88PD7SX|   27925116|0029148510|      72387289| 2005-10-14|\n","| RRS38KZ4WB5O2|   15005044|1592285570|     702385650| 2005-10-14|\n","|R2YDYRSLGNHPHR|   52534781|0811848833|     102333549| 2005-10-14|\n","|R1BMPM18O6VZOR|   26217071|0782144276|     971452783| 2005-10-14|\n","|R1AABFZH0J0C0C|   37684582|0375757996|     760991156| 2005-10-14|\n","|R3SJYLG07EHNE9|   45232107|013146308X|     332774292| 2005-10-14|\n","|R2TIO43ND87XVO|   15437121|0375701907|     635714194| 2005-10-14|\n","|R18TY4WD19OUAO|   52157117|141378240X|     656010659| 2005-10-14|\n","+--------------+-----------+----------+--------------+-----------+\n","only showing top 20 rows\n","\n"]}],"source":["from pyspark.sql.functions import to_date\n","# Create the \"review_id_df\" DataFrame with the appropriate columns and data types.\n","\n","review_id_df = books_df.select([\"review_id\", \"customer_id\", \"product_id\", \"product_parent\", \"review_date\"])\n","review_id_df.show()"]},{"cell_type":"markdown","source":["## Create the \"products\" Table"],"metadata":{"id":"aAVCFjXhtXO8"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"g9gTNhT62je4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a018060b-1352-4847-ee66-645d9b96cabf","executionInfo":{"status":"ok","timestamp":1669858602295,"user_tz":300,"elapsed":40594,"user":{"displayName":"Anisha Chaudhari","userId":"04176206645505870001"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+--------------------+\n","|product_id|       product_title|\n","+----------+--------------------+\n","|0029148510|Acts of War: Beha...|\n","|1844494896|Waiting For Kate ...|\n","|0451216954|Dark Lover (Black...|\n","|006056718X|Often Wrong, Neve...|\n","|0965852768|101 Spooktacular ...|\n","|141960435X|Flip Flop Spanish...|\n","|0471282502|Experimental Orga...|\n","|0756613647|Universe: The Def...|\n","|B0006YGCE8|Seismic risk asse...|\n","|207030602X|L Etranger (Folio...|\n","|1569711224|Aliens: Hive  (2n...|\n","|0756613744|Go Figure!: A Tot...|\n","|0891073825|The Cross: God's ...|\n","|1595140840|            Teach Me|\n","|1844491412|Led Zeppelin: The...|\n","|0060737980|Surrounded by Idi...|\n","|0486265250|Ancient Egyptian ...|\n","|0763627798|           Shoe Baby|\n","|097559950X|Natural Cures \"Th...|\n","|0595362478| Accursed Inhabitant|\n","+----------+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["# Create the \"products_df\" DataFrame that drops the duplicates in the \"product_id\" and \"product_title columns. \n","\n","products_df = books_df.select([\"product_id\",\"product_title\"])\n","products_df = products_df.dropDuplicates()\n","products_df.show()"]},{"cell_type":"markdown","source":["## Create the \"customers\" Table"],"metadata":{"id":"LJHuZ9zut0e5"}},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_pF2Vf3c2n2O","outputId":"2f9ba6ab-931a-4e14-fe9e-0b98b3224531","executionInfo":{"status":"ok","timestamp":1669858645897,"user_tz":300,"elapsed":39243,"user":{"displayName":"Anisha Chaudhari","userId":"04176206645505870001"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+--------------+\n","|customer_id|customer_count|\n","+-----------+--------------+\n","|   28735044|             9|\n","|   15607794|             1|\n","|   15596972|             1|\n","|   32371281|             2|\n","|   12084021|             1|\n","|   14462635|             1|\n","|   41052840|             5|\n","|   52068296|           105|\n","|   51739623|             1|\n","|   14544320|             1|\n","|   50093726|           151|\n","|   52925615|             1|\n","|   12266315|             1|\n","|   44917096|             1|\n","|   52833886|             1|\n","|   51854558|            57|\n","|   12404586|             2|\n","|   49850307|             8|\n","|   23478170|             1|\n","|   51088740|             1|\n","+-----------+--------------+\n","only showing top 20 rows\n","\n"]}],"source":["# Create the \"customers_df\" DataFrame that groups the data on the \"customer_id\" by the number of times a customer reviewed a product. \n","\n","customers_df = books_df.groupby(\"customer_id\")\\\n","              .agg({\"customer_id\": \"count\"})\\\n","              .withColumnRenamed(\"count(customer_id)\", \"customer_count\")\n","customers_df.show()\n"]},{"cell_type":"markdown","source":["## Create the \"vine_table\"."],"metadata":{"id":"8SbTasxbuXGK"}},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WHQKbmCE2p3Q","outputId":"904f1891-2e4e-475f-a760-435fd5afc197","executionInfo":{"status":"ok","timestamp":1669858650657,"user_tz":300,"elapsed":273,"user":{"displayName":"Anisha Chaudhari","userId":"04176206645505870001"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------+-----------+-------------+-----------+----+\n","|     review_id|star_rating|helpful_votes|total_votes|vine|\n","+--------------+-----------+-------------+-----------+----+\n","| RQ58W7SMO911M|          4|            2|          3|   N|\n","|  RF6IUKMGL8SF|          3|            5|          5|   N|\n","|R1DOSHH6AI622S|          4|            1|         22|   N|\n","| RATOTLA3OF70O|          5|            2|          2|   N|\n","|R1TNWRKIVHVYOV|          4|            0|          2|   N|\n","|R2F53LI9KK9MOY|          4|            2|          2|   N|\n","|R1KJ6MB7MRSQFF|          4|            9|         11|   N|\n","|R2XIM9LT335WHE|          4|            3|         10|   N|\n","|R1VE0FQQ0QTQJN|          5|           16|         20|   N|\n","|R1VKEE2NWSWDRU|          4|            0|          0|   N|\n","|R2UP6XSVYJBJ2H|          5|            0|          0|   N|\n","|R21SYDQ70ILUC0|          5|            1|          1|   N|\n","| R7M06Z88PD7SX|          4|           14|         14|   N|\n","| RRS38KZ4WB5O2|          5|            1|          1|   N|\n","|R2YDYRSLGNHPHR|          4|           16|         19|   N|\n","|R1BMPM18O6VZOR|          4|           13|         14|   N|\n","|R1AABFZH0J0C0C|          3|           17|         35|   N|\n","|R3SJYLG07EHNE9|          2|           16|         34|   N|\n","|R2TIO43ND87XVO|          5|            1|          1|   N|\n","|R18TY4WD19OUAO|          5|            1|          1|   N|\n","+--------------+-----------+-------------+-----------+----+\n","only showing top 20 rows\n","\n"]}],"source":["# Create the \"vine_df\" DataFrame that has the \"review_id\", \"star_rating\", \"helpful_votes\", \"total_votes\", and \"vine\" columns. \n","\n","vine_table_df = books_df.select([\"review_id\", \"star_rating\", \"helpful_votes\", \"total_votes\", \"vine\"])\n","vine_table_df.show()"]},{"cell_type":"markdown","metadata":{"id":"I8aTsEjZ2s6L"},"source":["# Load"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"W4dzUKfI2vXM","executionInfo":{"status":"ok","timestamp":1669864494534,"user_tz":300,"elapsed":529,"user":{"displayName":"Anisha Chaudhari","userId":"04176206645505870001"}}},"outputs":[],"source":["mode = \"append\"\n","jdbc_url=\"jdbc:postgresql://amazondb.czjhv6exdvb9.us-east-1.rds.amazonaws.com:5432/amazon_review_db\"\n","config = {\"user\":\"postgres\", \"password\": \"Suckers2!\", \"driver\":\"org.postgresql.Driver\"}"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"iOxKqMsD2yVs","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1669864517274,"user_tz":300,"elapsed":10357,"user":{"displayName":"Anisha Chaudhari","userId":"04176206645505870001"}},"outputId":"bd1b44c2-8634-44a2-bf53-0f15c3501962"},"outputs":[{"output_type":"error","ename":"Py4JJavaError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-40d02fe03a8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Write review_id_df to table in RDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreview_id_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjdbc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"reviews\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mjdbc\u001b[0;34m(self, url, table, mode, properties)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0mjprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n","\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o160.jdbc.\n: org.postgresql.util.PSQLException: The connection attempt failed.\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:292)\n\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)\n\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:211)\n\tat org.postgresql.Driver.makeConnection(Driver.java:458)\n\tat org.postgresql.Driver.connect(Driver.java:260)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:49)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:97)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:97)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:93)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:93)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:78)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:115)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:745)\n\tat jdk.internal.reflect.GeneratedMethodAccessor42.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.net.SocketTimeoutException: connect timed out\n\tat java.base/java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412)\n\tat java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255)\n\tat java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237)\n\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.base/java.net.Socket.connect(Socket.java:609)\n\tat org.postgresql.core.PGStream.<init>(PGStream.java:75)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:91)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:192)\n\t... 49 more\n"]}],"source":["# Write review_id_df to table in RDS\n","review_id_df.write.jdbc(url=jdbc_url, table=\"reviews\", mode=mode, properties=config)"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"pPXyGVE-2yPJ","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1669864812518,"user_tz":300,"elapsed":10335,"user":{"displayName":"Anisha Chaudhari","userId":"04176206645505870001"}},"outputId":"f675eeab-83e2-4970-e68e-154286ad9c53"},"outputs":[{"output_type":"error","ename":"Py4JJavaError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-03a6c62713fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Write products_df to table in RDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mproducts_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjdbc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"products\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mjdbc\u001b[0;34m(self, url, table, mode, properties)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0mjprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n","\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o165.jdbc.\n: org.postgresql.util.PSQLException: The connection attempt failed.\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:292)\n\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)\n\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:211)\n\tat org.postgresql.Driver.makeConnection(Driver.java:458)\n\tat org.postgresql.Driver.connect(Driver.java:260)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:49)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:97)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:97)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:93)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:93)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:78)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:115)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:745)\n\tat jdk.internal.reflect.GeneratedMethodAccessor42.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.net.SocketTimeoutException: connect timed out\n\tat java.base/java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412)\n\tat java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255)\n\tat java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237)\n\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.base/java.net.Socket.connect(Socket.java:609)\n\tat org.postgresql.core.PGStream.<init>(PGStream.java:75)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:91)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:192)\n\t... 49 more\n"]}],"source":["# Write products_df to table in RDS\n","products_df.write.jdbc(url=jdbc_url, table=\"products\", mode=mode, properties=config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aHbca4zN2yIa"},"outputs":[],"source":["# Write customers_df to table in RDS\n","customers_df.write.jdbc(url=jdbc_url, table=\"customers\", mode=mode, properties=config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2HfOFneW2x_F"},"outputs":[],"source":["# Write vine_df to table in RDS\n","vine_table_df.write.jdbc(url=jdbc_url, table='vine_table', mode=mode, properties=config)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}